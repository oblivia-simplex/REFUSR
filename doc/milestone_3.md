---
title: "ReMath Milestone 3 Report: REFUSR"
author: [add your names here]
date: \today
---




# "Refuduino": A PLC Busybox 

The "Refuduino" provides a physical platform to demonstrate the effects of the REFUSR System. It consists of a Raspberry Pi 4("RPi") single-board computer(SBC) running OpenPLC[1], an IEC 61131-3 Compliant Open Source Industrial Controller and an Arduino Nano microcontroller wired together at their respective I/O pins. This provides us with a physical platform to demonstrate that code effects generated by the GA-generated programs can be observed & recovered from a physical system and that these effects can be something as simple as a logical truth table. In other words, bits can be real switches, gates can open/close literal flood gates, etc. 

## Interconnects between RPi and Arduino


| ST Code  | RPi Pinouts| Arduino Code |
| --------:|:--------:|:-------- |
|![](https://i.imgur.com/Q2e0X5A.png)|![](https://i.imgur.com/2YawzCv.png)|![](https://i.imgur.com/QddTtCo.png)

Note that the VAR declarations in the partial ST code listing on the left correspond with the labels of the GPIO diagram in the center. Input pins on the Pi correspond to output pin declarations on the Arduino code listing on the right. The Fritzing[ref. here] diagram below details the actual wiring between the two devices. 

## Fritzing Diagram of "Refuduino" 
![](https://i.imgur.com/U7954Qz.png)

## Demo Video
The link below leads to a video demonstrating the current state of the REFUSR hardware system. The LED activity shows bits being written to the %IX0.n registers, the generate symbolic expression being computed over these bits with respective LEDs indicating the completion of the evaluation and the result written to %QX0.2. An analogue would be the status-and-register-state front-panel from a 1960s-era minicomputer. 

[Video demonstrating the REFUSR "Refuduino" Hardware.](https://drive.google.com/file/d/13FMq_jDUwdXnWMap4CDXmleHOR8yoFkw/view?usp=sharing)




# Foundations of the Property Testing Library: Junta Testing

## Adaptive Junta Testing

Based on a preliminary literature review, we identified as state-of-the-art the adaptive junta tester described in “Distribution-Free Junta Testing,” Zhengyang Liu, Xi Chen, Rocco A. Servedio, Ying Sheng, and Jinyu Xie. STOC’18, June 25–29, 2018, Los Angeles, CA, USA. The algorithm 

“Adaptive” refers to not assuming but rather being adaptable to an input distribution of interest. This permits a better theoretical performance, with a polynomial rather than exponential query complexity, and also makes it possible to directly use empirical execution data to learn the probability distribution that the junta tester samples from, so that its results can be most a propos of the part of the input space that is most relevant in practice.

### Novel Automatic Order Search

The algorithm as developed and described in the source paper could only test the junta property of a given order. That is, the junta predicate checking algorithm took the number of input bits _k_ as a parameter and could only reply with an acceptance or probabilistic rejection of a junta of that order.

By identifying the state that should be shared across iterations as the partial list of input bits with a proven influence on the output at some point in the input space, we were able to modify the algorith to share this state across searches of increasing junta order and thus to automatically identify the junta order and also to explicitly indicate the set of inputs in the junta.

### Preliminary Benchmarks

We evaluated the performance of the junta checker on artificial test cases designed to both stress the worst-case scaling behavior of the algorithm as input space increases and to evaluate a hypothesis about the characteristics of the search space that might prove challenging at a fixed junta order.

We designed two artificial function families with a fixed junta order, and ran experiments with increasing total input space size, so that the junta-forming inputs would grow more and more sparse among all the nominal inputs, a behavior that is a worst-case instance of a pattern that is expected to be common in naturally occurring functions with significant control flow, where, because of clipping of the output behavior at boundaries established by conditionals, most of the input bits associated with such inputs will yield values at conditional expressions that do not influence branches taken, and thus do not influence the outputs. Within this class, we posited a “hard” function and an “easy” function, where the easy one was constructed as a XOR of a subset of 9  of the inputs, and hard one was the same function but also constructed to be constant on a different 3 bit subplane of the inputs, with the intent of depriving the algorithm of variability information on a significant part of the input space by masking the variability in the XORed inputs. Nonetheless, the expectations reflected in the names did not obtain, and the so-called hard function took less time to solve than the so-called easy one, as if it had about 2 fewer bits in the input space. This suggests that the query complexity of the tester has a stricter dependency on the number of bits influencing the output than expected, regardless of dependencies among bits in the input space with respect to determining the output. This informed the development of distribution modeling techniques that can either represent or ignore such dependencies (see below).

In either case, the scaling appeared at least exponential in the size of the input space, reflecting the search over power sets of decreasing sets of the inputs taking place in the algorithm. We ran experiments from 9 to 20 bits in the input space, and obtained the results depicted below.

![](https://i.imgur.com/fFv77Sl.png)


## Distribution Modeling

The adaptive junta checker requires the input distribution that samples are drawn from for checking to be specified, and ensuring that this distribution approximates the empirical distribution of inputs to the function under consideration concentrates the tester's efforts in regions of the input space most likely to be encountered in practice and thus ensures the results of checking are biased as much as possible toward inputs of practical interest.

To that end, we developed three methods of specifying the input distribution. The first uses a fixed, symmetric beta distribution between zero and one for each bit, which plays the role of an uninformative prior that is slightly biased toward bit vectors of an equal number of one and zero bits.

Two other data-adaptive methods were also developed. The second is based on iteratively increasing clustering with k-means and builds a mixture model of the empirical distribution. It is capable of learning, representing, and yielding samples from a multimodal distribution, and inference is reasonably efficient since, like the junta tester itself, it was developed to share state between models when testing a model of different dimension. It was found to be able to exactly identify the canonical basis for the three dimensional binary space from much higher dimensional data.

The third method fits a vector of Bernoulli random variables to the data, and permits smoothing of the distribution. It thus cannot represent higher-order dependencies among variables or multiple modes, but is simple, fast, and by being less biased away from uniform can serve an intermediate role between the uninformative prior and the mixture model.

### Towards General Property Testing

Briefly, finding a junta is a useful preprocessing step for focusing sampling for testing other properties only on inputs which are capable of influencing the output of a function under scrutiny. We are moving on to develop more general property testing according to the framework in Chapter 6 of Oded Goldreich, _Introduction to Property Testing,_ 2021 that builds on the junta tester.

# The Cockatrice GP Framework and the REFUSR System (In Progress)

![](https://i.imgur.com/A9PEjMh.png)

`Cockatrice.jl` is a general genetic programming (GP) framework that are developing for use in the REFUSR project (and its sister project, ROPER, which was partially developed under the AIMEE contract, but which falls outside the scope of ReMath). What Cockatrice provides in this case is a multiprocessing system that takes care of the basic evolutionary search architecture: a collection of geographically structured "island" populations are maintained, abstracting away from the details of individual genotypes, their phenotypic expression, and fitness functions, and tournament selection is scheduled and dispatched. 

## Design Decisions






### Linear Genetic Programming in REFUSR

When designing the GP system used in REFUSR, itself, we first considered using a tree-based form of GP, in the tradition of John Koza, where each individual genotype is represented as an abstract syntax tree or symbolic expression. The idea here was that since we're ultimately looking to evolve program specifications (constrained by problem sets and inferred properties), it would be nice if our genotype representation was _already_ "human readable", or expressible as a clear algebraic expression.

This brought us up against certain obstacles in memory and runtime efficiency, however, so we opted for Banzhaf-style linear GP instead, where programs are represented as a sequence of imperative instructions for a virtual register transfer machine -- something resembling an assembly language for a simple architecture. 

A **linear program** is a vector of **register transfer instructions**, which in the context of this report we will simply call "instructions". Each instruction is a structure with three degrees of freedom: 

1. choice of source register
2. choice of destination register
3. choice of operator

When an instruction is executed on the VM, the operands are fetched from the registers -- from the source register, if the operator takes just one argument, or from the source and destination registers, if the operator takes two. The result of applying the operator to these arguments is then stored in the destination register.

In the context of this report, the term **genotype**, unless otherwise specified, will refer to just these linear programs.

For the time being we're doing without jumps and conditionals. This both eases the translation between linear programs and symbolic expressions, and allows us to execute programs in a massively parallel fashion. Rather than evaluating a function of type $f: \mathbb{B}^n \rightarrow \mathbb{B}^1$ for each of $m$ test cases, we can vectoralize our instruction set and evaluate a function of type $f: \mathbb{B}^{mn} \rightarrow \mathbb{B}^m$, sweeping over every test case at once. 

Crucially, every linear program of jump-free register transfer instructions will eventually halt -- indeed, a program of length $\ell$ will halt after exactly $\ell$ steps. 

It should be noted that _every concatenation of register transfer instructions_ constitutes a valid linear program. The only restriction we impose is on length, for which we set an upper bound, configurable for each experiment, in order to guard against the exhaustion of computational resources.

#### The Probability Distribution of Linear Programs

The set of linear programs under length $\ell$ is easy to sample from with uniform probability. The distribution of instructions, $\mathbb{INST}$, is just the product of the three independent distributions of available source registers, destination registers, and operators.

$$\mathbb{INST} = \mathbb{SRC} \times \mathbb{DST} \times \mathbb{OP}$$

The distribution of programs of length $\ell$, similarly, is just 

$$\mathbb{INST}^\ell = \mathbb{INST}_1 \times \mathbb{INST}_2 \times \dots \times \mathbb{INST}_\ell$$

To sample uniformly from the space of possible programs of length $\ell$, all that needs to be done is to independently select $\ell$ instructions -- much in the same way that to sample uniformly from the set of 64-bit integers it is sufficient to flip a fair coin 64 times.



### An Argument for Immutable Input Registers and Mutable Scratch Registers

By **machine state**, here, we will mean only the register vector, as this is the only struture in the VM that our instructions are able to influence. The program counter increments inexorably with each instruction's execution, since there are no jumps, so we can ignore it in the following discussion.

Before each program is executed, the virtual machine is initialized by setting all registers to zero, except for a subset of **input registers**, $D$, which are loaded with the input values for a given test case. Between initialization and termination, nothing but the program itself is allowed to influence the machine state.

Linear programs, as understood in this context, are deterministic. The effect of an instruction is uniquely determined by the machine state.

Consider the quantity of information, or entropy, contained in the machine state after initialization. With the execution of any given instruction, one of two things can happen: either the entropy level decreases or it remains constant. There is no way for entropy to increase.



| Information Preserving | Information Destroying | Depends on Context |
| -------- | -------- |-----|
| `R[1] := R[1] & true` | `R[1] := R[1] & false`     | `R[1] := R[1] & R[2]`|
| `R[1] := R[1] \| false` | `R[1] := R[1] \| true` | `R[1] := R[1] \| R[2]` |
| `R[1] := ~R[1]` | `R[1] := R[1] xor R[1]` | `R[1] := R[1] xor R[2]` |


Under these conditions, as program length increases, so does the probability that that program computes a constant function. So long as there is _some_ probability of encountering information-destroying instructions and instruction combinations, the loss of information will accumulate, bit by bit, until the output of the program in no way depends on input.

And since programs reproduce by division and concatenation, if a subsegment of a program is information-destroying, that loss will be inherited by its offspring.

Forcing the input registers to be _immutable_ by removing them from the set of possible destination registers acts as a guard rail against information loss, and it ensures that any program whatsover can be rehabitated by an appropriate suffix. This is a simple way to protect the population's computational resources.

In our implementation, the input registers $D$ are immutable -- they can be chosen as an instruction's source register but never destination -- while a set of mutable scratch registers, $R$, are allowed act as both source and destination.



### Decompilation and Simplification


In order for our results to be of any use to a subject area expert, we translate the programs that constitute our genetic representations into concise symbolic expressions (the absence of jumps and conditionals greatly simplifies this process as well).


REFUSR's linear genotypes are composed of a series of primitive register transfer instructions. They resemble assembly code for a simple virtual machine.

~~~{.asm}
TODO: example, use a 4-to-1 mux champion, and then show the
decompiled expression as well.
~~~

Internally, each instruction is defined as a Julia `struct`, with fields for the source and destination register, the operator (a function), and that operator's arity. (Though we're currently not using any, since they invariably destroy execution information and inhibit evolutionary search, constants can be defined as nullary functions in this fashion, by setting the arity field to zero, and the operator field to `() -> true` or `() -> false`.)

We can translate each instruction to a simple symbolic expression -- indeed, a member of the Julia `Expr` type -- that expresses an assignment. 

~~~{.julia}

function to_expr(inst::Inst)
    op = nameof(inst.op)
    dst = :(R[$(inst.dst)])
    src_t = inst.src < 0 ? :D : :R
    src_i = abs(inst.src)
    src = :($(src_t)[$(src_i)])
    if inst.arity == 2
        :($dst = $op($dst, $src))
    elseif inst.arity == 1
        :($dst = $op($src))
    else # inst.arity == 0
        :($dst = $(inst.op()))
    end
end
~~~


A sequence of instructions can then be composed into a single assignment expression by performing a series of subexpression replacements, while iterating backwards through the instruction sequence. Whenever we encounter an assignment of the form `lhs := rhs`, we simply replace all occurrences of the subexpression `lhs` with the expression `rhs` in our accumulated expression. 

When the iteration is complete, we are left with a cumulative assignment instruction, which has the output register (`R[1]`) on the left-hand side, and the compound expression, generated through successive replacements, on the right. 

~~~{.julia}
function to_expr(code::Vector{Inst}; incremental_simplify=true)
    code = strip_introns(code, [1])
    if isempty(code)
        # If there's no code to execute, R[1] remains 0
        return false 
    end
    expr = pop!(code) |> to_expr
    LHS, RHS = expr.args
    while !isempty(code)
        e = pop!(code) |> to_expr
        lhs, rhs = e.args
        RHS = Expressions.replace(RHS, lhs=>rhs)
    end
    # Since we initialize the R registers to `false`, any remaining R references
    # can be replaced with `false`.
    Expressions.replace(RHS, (e -> e isa Expr && e.args[1] == :R) => false)
end
~~~

When this function terminates, the only remaining variables in the expression will be those which correspond to the immutable input registers, and the program appears as a pure Boolean function over the inputs.

### Simplifying Symbolic Expression Trees

#### Incremental Simplification

The cost of expression simplification grows explosively with the size of the expression, and worst-case expression complexity tends to grow with the length of the instruction list. And, in general, as a population of programs evolves, in search of a target function, there will tend to be a complexification of implicit logical structure in those programs. For these reasons, it's often better to apply the simplification algorithm incrementally, after each replacement operation in the decompilation algorithm, than it is to wait for the entire list to be decompiled into a single complex expression before simplification begins.





#### Caching

`evoL`, here, is a new, single-island population of 100 genotypes, each with a maximum code length of 100, using 6 immutable input registers, `D[1:6]` and 6 mutable scratch registers, `R[1:6]`. `R[1]` is designated as the output register -- whichever value is held by `R[1]` at the end of execution is taken as the program's return value.

![Mean Naive Expression Complexity Over Time](https://i.imgur.com/OYQTHoE.png)


The exact numbers can vary wildly from run to run, even when, as here, we begin with identical initial populations. But the expression complexity of the naively decompiled programs is _consistently_ orders of magnitude greater than what we find in the simplified program, and growing at a tremendously accelerated rate.

![Mean naive expression complexity over time, a second trial](https://i.imgur.com/0L6SGGj.png)


And it only gets worse from there, for the naive method of expression decompilation, while our simpification technique appears to consistently suppress expression bloat.

![Mean naive expression complexity over time, after 1000 tournaments](https://i.imgur.com/VrXD6TY.png)


By utilizing a 512 mibibyte cache with the `simplify()` function, we're able to obtain an impressive, 100x speedup when decompiling a virgin, unevolved population.

~~~ {.julia}
julia> Expressions._use_cache(false); Expressions.flush_cache!()
LRU{Expr, Union{Bool, Expr, Symbol}}(; maxsize = 1048576)

julia> @btime s = LinearGenotype.decompile(rand(evoL.geo.deme), cache=false)
908.448 μs (3226 allocations: 281.33 KiB)
true

julia> Expressions._use_cache(true); Expressions.flush_cache!()
LRU{Expr, Union{Bool, Expr, Symbol}}(; maxsize = 1048576)

julia> @btime s = LinearGenotype.decompile(rand(evoL.geo.deme), assign=false)
8.610 μs (57 allocations: 2.39 KiB)
:(D[1])
~~~

Now, naive (unsimplified) expression complexity tends to increase as the population evolve (TODO: plot this!), as more or less coherent logical structure begins to crystalize in the soup of once merely random instructions. This makes the simplification algorithm increasingly costly to run. Indeed, before we implemented incremental simplification in the decompilation algorithm, simplifying genome at a late stage in the evolution would often take upwards of 30 minutes, if it didn't exhaust the memory of our workstation entirely.

Furthermore, since the population evolves through recombinatorial (and sometimes mutational) means -- even though this is at the level of linear instructions and not symbolic expressions -- we should expect common subexpressions to recur quite frequently, which makes a compelling case for caching.

~~~ {.julia}
julia> @showprogress for i in 1:1000 Step.do_step!(evoL); end
Progress: 100%|██████████████████████████████████████████████████████| Time: 0:00:05

julia> Expressions._use_cache(true); Expressions.flush_cache!()
LRU{Expr, Union{Bool, Expr, Symbol}}(; maxsize = 1048576)

julia> @btime s = LinearGenotype.decompile(rand(evoL.geo.deme), assign=false)
  29.740 μs (200 allocations: 8.66 KiB)
:((D[5] & (D[1] | D[6])) & (D[2] | D[3]))

julia> Expressions._use_cache(false); Expressions.flush_cache!()
LRU{Expr, Union{Bool, Expr, Symbol}}(; maxsize = 1048576)

julia> @btime s = LinearGenotype.decompile(rand(evoL.geo.deme), cache=false)
  109.895 ms (36699 allocations: 3.11 MiB)
:(((D[1] | D[6]) & (D[3] | D[4])) & (D[5] | D[6]))
~~~

#### Alpha-Reduction Invariant Caching

Since the possibilities for simplifying an expression do not depend on the particular choice of variable names, it would be a waste of time to perform the expensive computations involved in simplifying an expression $e$ if we have already simplified $e'$, so long as $e$ can be produced by renaming the variables in $e'$, in a one-to-one fashion. In the terminology of $\lambda$-calculus, $e$ and $e'$ are thus said to be $\alpha$-equivalent, or equivalent modulo $\alpha$-reduction.

Our caching algorithm captures this intuition by applying a canonical variable renaming on expressions and their simplifications before entering them into the cache, and by applying the same renaming scheme on an expression before consulting the cache for known simplifications.

~~~{.julia}
function check_cache(e)
    try
        α, mapping = rename_variables(e)
        result_α = CACHE[α] # may throw a KeyError
        return restore_variables(result_α, mapping)
    catch er # KeyError
        if !(er isa KeyError) throw(er) end
        return nothing
    end
end

function cache(e, result)
    e_α, mapping = rename_variables(e)
    result_α, _ = rename_variables(result; mapping)
    CACHE[e_α] = result_α
end
~~~

The renaming scheme itself is simple: we perform a pre-order traversal on the expression (any fixed traversal scheme will do), and whenever we encounter a new variable, we choose a new name for it from a fixed list of variable names that we know do not occur in the expression. 

~~~{.julia}
function alpha_mapping(e; letter=:α)
    vars = variables_used(e)
    α = [:($(letter)[$(i)]) for i in 1:length(vars)]
    zip(vars, α)
end

function rename_variables(e::Expr; letter=:α, mapping=alpha_mapping(e;letter))
    e_α = subs(e, Dict(mapping))
    return (e_α, mapping)
end

function restore_variables(e::Expr, mapping)
    subs(e, Dict((v,a) for (a,v) in mapping))
end
~~~

For example, this gives us:

~~~{.julia}
e = :((~(D[2] ⊻ D[3]) | (D[4] & D[1] ⊻ (D[1] | D[2]))) ⊻ D[4])
D[2] --> α[1]
D[3] --> α[2]
D[4] --> α[3]
D[1] --> α[4]
α = :((~(α[1] ⊻ α[2]) | (α[3] & α[4] ⊻ (α[4] | α[1]))) ⊻ α[3])

~~~

Any expression that is $\alpha$-equivalent to $e$ will be mapped to the exact same expression by our `rename_variables()` function. (It follows, incidentally, that this renaming operation is idempotent.)

$$\forall e\forall x \left(x \equiv^\alpha e \implies \texttt{rename_variables(}x\texttt{)[1]} = \texttt{rename_variables(}e\texttt{)[1]}\right)$$


### Geographical Distribution

In this particular example, for the sake of simplicity, we'll look at a single island (and single process) evolution. Each island can be structured as the surface of an n-dimensional torus, but we'll stick to two dimensions here. When a tournament is arranged, Cockatrice begins by chosing a random point on the island, and then randomly selects competitors from the neighbourhood of that point. The closer an individual is to the point in question, the more likely their participation in that tournament becomes. The steepness of the distribution curve around that point can be adjusted by tweaking the `locality` parameter in the system's configuration file.

<img src="https://i.imgur.com/DKBaDbn.png" height="500px" alt="Geographically constrained tournament delegation weights, on a 2-dimensional toroidal geometry">


![Five samples of tournament batches](https://i.imgur.com/lIHvtIk.jpg)


## 4-to-1 Multiplexor Experiment

![Circuit diagram of a 4-to-1 multiplexor (MUX)](https://i.imgur.com/44qOigJ.png)

(TODO: Find consistent looking diagrams for the multiplexers)

### Configuration

```
experiment_duration: 1500
preserve_population: true

selection:
  fitness_function: "fit"
  data: "./samples/2-MUX_overs-cohos-orbed_ALL.csv"
  d_fitness: 3
  t_size: 6
  fitness_sharing: true

genotype:
  max_depth: 8
  min_len: 4
  max_len: 500
  inputs_n: 7
  output_regs: [1]
  max_steps: 512
  mutation_rate: 0.1

population:
  size: [12, 12]
  toroidal: true
  locality: 16
  n_elites: 10
  migration_rate: 0.1
  migration_type: "elite"

logging:
  log_every: 1
  save_every: 50

```

### Target as a Symbolic Expression

```
:((((~(~(D[3]) & ~(D[1])) | D[2]) & (~(D[3] & ~(D[1])) | D[6])) & (~(~(D[3]) & D[1]) | D[4])) & (~(D[3] & D[1]) | D[5]))
```

### Target as a Structured Text (ST) Program

```
(*
This code implements a shuffled multiplexer with 2 control bits.
The control bits are: Data[3], Data[1]
The input bits are: Data[2], Data[6], Data[4], Data[5]

The symbolic expression is:
(((~(~(D[3]) & ~(D[1])) | D[2]) & (~(D[3] & ~(D[1])) | D[6])) & (~(~(D[3]) & D[1]) | D[4])) & (~(D[3] & D[1]) | D[5])

*)

FUNCTION_BLOCK F_CollectInput
  VAR_IN_OUT
      Data : ARRAY[1..10] OF BOOL;
  END_VAR
  VAR_INPUT
      TICK  : BOOL := 0;
      IN1   : BOOL := 0;
      IN2   : BOOL := 0;
      IN3   : BOOL := 0;
      IN4   : BOOL := 0;
      IN5   : BOOL := 0;
      RESET : BOOL := FALSE;
  END_VAR
  VAR_OUTPUT
      Finished : BOOL;
  END_VAR
  VAR
      j    : USINT := 1;
      tock : BOOL  := 0;
  END_VAR
  IF NOT RESET AND tock = NOT TICK THEN
      Data[j]   := IN1;
      Data[j+1] := IN2;
      Data[j+2] := IN3;
      Data[j+3] := IN4;
      Data[j+4] := IN5;
      j := j + 5;
      tock := TICK;
  ELSE
      j := 1;
      tock := 0;
  END_IF;
  Finished := (j > 10);
END_FUNCTION_BLOCK


PROGRAM Boiler
  VAR
    Data  : ARRAY[1..10] OF BOOL;
    Ready : BOOL;
    CollectInput : F_CollectInput;
  END_VAR
  VAR
    TICK     AT %IX1.0 : BOOL;
    IN1      AT %IX0.3 : BOOL;
    IN2      AT %IX0.4 : BOOL;
    IN3      AT %IX0.5 : BOOL;
    IN4      AT %IX0.6 : BOOL;
    IN5      AT %IX0.7 : BOOL;
    OutReady AT %QX0.0 : BOOL := FALSE;
    FeedNext AT %QX0.1 : BOOL := FALSE;
    Out      AT %QX0.2 : BOOL;
  END_VAR
  CollectInput(TICK:=TICK, IN1:=IN1, IN2:=IN2, IN3:=IN3, IN4:=IN4, IN5:=IN5);
  Ready := CollectInput.Finished;
  FeedNext := 1;
  IF Ready THEN
    Out := (((((NOT ((NOT D[3]) AND (NOT D[1]))) OR D[2]) AND ((NOT (D[3] AND (NOT D[1]))) OR D[6])) AND ((NOT ((NOT D[3]) AND D[1])) OR D[4])) AND ((NOT (D[3] AND D[1])) OR D[5]));
    OutReady := 1;
    CollectInput(RESET:=TRUE);
  END_IF;
END_PROGRAM


CONFIGURATION Config0
  RESOURCE Res0 ON PLC
    TASK task0(INTERVAL := T#20ms,PRIORITY := 0);
    PROGRAM instance0 WITH task0 : Boiler;
  END_RESOURCE
END_CONFIGURATION
```

### Target as Truth Table

|D[1]|D[2]|D[3]|D[4]|D[5]|D[6]|OUT|
|----|----|----|----|----|----|---|
|0   |0   |0   |0   |0   |0   |0  |
|1   |0   |0   |0   |0   |0   |0  |
|0   |1   |0   |0   |0   |0   |1  |
|1   |1   |0   |0   |0   |0   |0  |
|0   |0   |1   |0   |0   |0   |0  |
|1   |0   |1   |0   |0   |0   |0  |
|0   |1   |1   |0   |0   |0   |0  |
|1   |1   |1   |0   |0   |0   |0  |
|0   |0   |0   |1   |0   |0   |0  |
|1   |0   |0   |1   |0   |0   |1  |
|0   |1   |0   |1   |0   |0   |1  |
|1   |1   |0   |1   |0   |0   |1  |
|0   |0   |1   |1   |0   |0   |0  |
|1   |0   |1   |1   |0   |0   |0  |
|0   |1   |1   |1   |0   |0   |0  |
|1   |1   |1   |1   |0   |0   |0  |
|0   |0   |0   |0   |1   |0   |0  |
|1   |0   |0   |0   |1   |0   |0  |
|0   |1   |0   |0   |1   |0   |1  |
|1   |1   |0   |0   |1   |0   |0  |
|0   |0   |1   |0   |1   |0   |0  |
|1   |0   |1   |0   |1   |0   |1  |
|0   |1   |1   |0   |1   |0   |0  |
|1   |1   |1   |0   |1   |0   |1  |
|0   |0   |0   |1   |1   |0   |0  |
|1   |0   |0   |1   |1   |0   |1  |
|0   |1   |0   |1   |1   |0   |1  |
|1   |1   |0   |1   |1   |0   |1  |
|0   |0   |1   |1   |1   |0   |0  |
|1   |0   |1   |1   |1   |0   |1  |
|0   |1   |1   |1   |1   |0   |0  |
|1   |1   |1   |1   |1   |0   |1  |
|0   |0   |0   |0   |0   |1   |0  |
|1   |0   |0   |0   |0   |1   |0  |
|0   |1   |0   |0   |0   |1   |1  |
|1   |1   |0   |0   |0   |1   |0  |
|0   |0   |1   |0   |0   |1   |1  |
|1   |0   |1   |0   |0   |1   |0  |
|0   |1   |1   |0   |0   |1   |1  |
|1   |1   |1   |0   |0   |1   |0  |
|0   |0   |0   |1   |0   |1   |0  |
|1   |0   |0   |1   |0   |1   |1  |
|0   |1   |0   |1   |0   |1   |1  |
|1   |1   |0   |1   |0   |1   |1  |
|0   |0   |1   |1   |0   |1   |1  |
|1   |0   |1   |1   |0   |1   |0  |
|0   |1   |1   |1   |0   |1   |1  |
|1   |1   |1   |1   |0   |1   |0  |
|0   |0   |0   |0   |1   |1   |0  |
|1   |0   |0   |0   |1   |1   |0  |
|0   |1   |0   |0   |1   |1   |1  |
|1   |1   |0   |0   |1   |1   |0  |
|0   |0   |1   |0   |1   |1   |1  |
|1   |0   |1   |0   |1   |1   |1  |
|0   |1   |1   |0   |1   |1   |1  |
|1   |1   |1   |0   |1   |1   |1  |
|0   |0   |0   |1   |1   |1   |0  |
|1   |0   |0   |1   |1   |1   |1  |
|0   |1   |0   |1   |1   |1   |1  |
|1   |1   |0   |1   |1   |1   |1  |
|0   |0   |1   |1   |1   |1   |1  |
|1   |0   |1   |1   |1   |1   |1  |
|0   |1   |1   |1   |1   |1   |1  |
|1   |1   |1   |1   |1   |1   |1  |



### Implicit Fitness Sharing and Interaction Matrices

One of the most serious hazards that an evolutionary process can encounter is a premature collapse of population diversity. This can happen when a particular genetic line $G$ acquires a decisive competitive advantage early in the process by performing very well on a subset $S \subset T$ of the test cases -- a significantly larger subset, let's say, than those handled by competing gene lines. It may be the case that $G$ lacks the computational resources to handle cases outside of $S$, but so long as the rewards meted out by the fitness function are proportionate to the number of cases correctly solved, without regard for the rarity or difficulty of solutions, we may soon see a population dominated almost entirely by recombinations of $G$, each exhibiting strikingly similar behaviour.

One way to offset such a premature convergence and loss of genetic information is to adjust the reward for a test case according to the frequency with which that test case has been successfully solved. This can easily be done by maintaining a data structure called an _interaction matrix_, a 2-dimensional array whose rows represent test cases and whose columns represent individuals in the population. `I[i,j]` is set to `1` if individual `j` solves test case `i`, and `0` otherwise. Each test case can then be assigned a "difficulty" score simply by subtracting the mean of its row from 1. Each individual then receives an award equal to the mean of the difficulty scores for the problems it's solved. 

~~~{.julia}
difficulty_scores = 1.0 .- map(mean, eachrow(INTERACTION_MATRIX))
correct_results   = (!).(answer_vector .⊻ result_vector) # 
adjusted_rewards  = correct_vector .* difficulty_scores
aggregate_reward  = mean(adjusted_rewards)
~~~







### Without fitness sharing


#### Distribution of Populations at End of Run

NOTE: these plots kind of suck. Put something better together on Monday night, I guess. 

![](https://i.imgur.com/D9NYWjx.png)

![](https://i.imgur.com/z8FAdTL.png)

#### Interaction Matrices

The loss of behavioural diversity in the poulation where fitness sharing is not in effect is evident to even a visual inspection of its interaction matrices, as shown below. Consistent bars of black and white, spanning multiple columns, indicates a lack of heterogeneity in the population. Note that horizontal locality does have some significance here, since the propagation of genes is probabilistically influenced by geographical structure, as noted earlier.



![Visualization of the interaction matrices of four islands early in the evolutionary process, without fitness sharing](https://i.imgur.com/UQJXati.png)



![The interaction matrices, 90 seconds in, in the populations without fitness sharing](https://i.imgur.com/gg0Ae0s.png)


![The interaction matrices in the populations without fitness sharing, at the end of a 1000-second run.](https://i.imgur.com/ewDzZ2F.png)


![Difficulty of the problem set over time without fitness sharing](https://i.imgur.com/sEtCK7t.png)


### With fitness sharing

#### Distribution of Populations at End of Run

![](https://i.imgur.com/oWher38.png)


![](https://i.imgur.com/K4kM0bb.png)


#### Interaction Matrices


![Visualization of the interaction matrices of four islands early in the evolutionary process, _with_ fitness sharing](https://i.imgur.com/W5czPSD.png)

![The interaction matrices, 90 seconds in, in the populations with fitness sharing](https://i.imgur.com/HDhGIDa.png)


![The interaction matrices in the populations _with_ fitness sharing, at the end of a 187-second run.](https://i.imgur.com/LeYNPhO.png)


![Difficulty of the problem set over time with fitness sharing](https://i.imgur.com/FWIgypO.png)


## 8-to-1 Multiplexor

![Circuit diagram of an 8-to-1 (11-bit) multiplexor](https://i.imgur.com/kxwEJxm.png)


### Solution in Linear Register Transfer Code (Unsimplified)

A solution was found after 88,810 tournaments, on one of eight migratory island subpopulations. 

```
R[02] ← ~ D[10]
R[04] ← ~ D[06]
R[01] ← ~ R[02]
R[01] ← R[01] & D[02]
R[04] ← R[04] & R[08]
R[02] ← ~ R[04]
R[07] ← R[07] & R[07]
R[08] ← ~ D[04]
R[04] ← R[04] | D[05]
R[04] ← R[04] | R[08]
R[04] ← R[04] & R[08]
R[07] ← R[07] & R[02]
R[10] ← ~ R[07]
R[11] ← ~ R[01]
R[11] ← R[11] & R[11]
R[11] ← R[11] | D[01]
R[11] ← R[11] | D[01]
R[11] ← R[11] & D[01]
R[05] ← ~ R[11]
R[11] ← R[11] & D[01]
R[06] ← ~ R[11]
R[10] ← R[10] & R[06]
R[11] ← ~ R[04]
R[01] ← R[01] | R[05]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[04] ← R[04] & R[10]
R[05] ← ~ R[11]
R[04] ← ~ R[04]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[04] ← R[04] & R[10]
R[08] ← R[08] & D[10]
R[04] ← R[04] | D[02]
R[06] ← ~ D[04]
R[04] ← R[04] & D[08]
R[10] ← R[10] & R[06]
R[01] ← R[01] & D[02]
R[04] ← R[04] & R[08]
R[07] ← ~ D[09]
R[10] ← R[10] & R[06]
R[11] ← ~ R[04]
R[07] ← R[07] | D[07]
R[07] ← R[07] | D[07]
R[01] ← R[01] | R[05]
R[07] ← R[07] | D[09]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] | R[07]
R[05] ← ~ R[11]
R[04] ← ~ R[04]
R[07] ← R[07] & D[04]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] & D[02]
R[07] ← R[07] & R[07]
R[06] ← ~ D[11]
R[09] ← ~ D[01]
R[02] ← ~ R[06]
R[02] ← R[02] & R[01]
R[11] ← ~ R[04]
R[04] ← ~ D[01]
R[10] ← R[10] & R[11]
R[11] ← R[11] | D[02]
R[08] ← ~ R[09]
R[04] ← R[04] & D[10]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] | R[07]
R[05] ← ~ R[11]
R[04] ← ~ R[04]
R[07] ← R[07] & D[04]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] & D[02]
R[02] ← R[02] & D[04]
R[07] ← R[07] & R[07]
R[06] ← ~ D[11]
R[09] ← ~ D[01]
R[05] ← R[05] | R[02]
R[02] ← ~ R[06]
R[02] ← R[02] & R[01]
R[11] ← ~ R[04]
R[05] ← R[05] & D[10]
R[11] ← R[11] | D[02]
R[05] ← R[05] | R[02]
R[08] ← ~ R[09]
R[03] ← ~ D[11]
R[03] ← R[03] & R[08]
R[05] ← R[05] & R[03]
R[03] ← R[03] & D[05]
R[05] ← R[05] | R[02]
R[03] ← R[03] & R[11]
R[06] ← ~ D[04]
R[11] ← R[11] | D[01]
R[07] ← R[07] | D[07]
R[11] ← R[11] & D[01]
R[03] ← R[03] | R[01]
R[07] ← R[07] & R[07]
R[11] ← R[11] | R[07]
R[03] ← R[03] & R[11]
R[10] ← ~ R[01]
R[07] ← ~ D[09]
R[02] ← ~ R[06]
R[03] ← R[03] & R[11]
R[04] ← ~ R[02]
R[03] ← R[03] | R[01]
R[03] ← R[03] | R[01]
R[03] ← R[03] | R[01]
R[11] ← ~ R[04]
R[06] ← ~ R[11]
R[03] ← R[03] & D[05]
R[07] ← R[07] | D[07]
R[01] ← R[01] | R[05]
R[06] ← R[06] & D[03]
R[07] ← R[07] | D[09]
R[01] ← R[01] & R[11]
R[10] ← R[10] & R[06]
R[01] ← R[01] & D[02]
R[11] ← R[11] | D[01]
R[07] ← R[07] | D[07]
R[08] ← ~ R[10]
R[01] ← R[01] | R[05]
R[07] ← R[07] | D[09]
R[01] ← R[01] & R[11]
R[01] ← R[01] & D[02]
R[04] ← R[04] & R[08]
R[11] ← R[11] | D[01]
R[11] ← R[11] | D[01]
R[07] ← R[07] | D[07]
R[11] ← R[11] & D[01]
R[03] ← R[03] | R[01]
R[07] ← R[07] & R[07]
R[11] ← R[11] | R[07]
R[03] ← R[03] & R[11]
R[10] ← ~ R[01]
R[06] ← ~ R[03]
R[02] ← ~ R[06]
R[02] ← R[02] & R[01]
R[11] ← ~ R[04]
R[02] ← R[02] & D[02]
R[02] ← R[02] & D[01]
R[01] ← R[01] & D[05]
R[01] ← R[01] | R[02]
R[11] ← R[11] & R[11]
R[07] ← ~ D[09]
R[11] ← R[11] | R[07]
R[11] ← R[11] & R[11]
R[07] ← ~ D[09]
R[11] ← R[11] | R[07]
R[07] ← ~ D[09]
R[04] ← ~ D[01]
R[10] ← R[10] & R[11]
R[11] ← R[11] | D[02]
R[07] ← R[07] | R[07]
R[07] ← R[07] | R[07]
R[05] ← ~ R[11]
R[11] ← ~ R[04]
R[04] ← ~ R[04]
R[07] ← R[07] & D[04]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] & D[02]
R[07] ← R[07] & D[02]
R[11] ← R[11] | D[02]
R[06] ← ~ R[11]
R[07] ← R[07] | R[07]
R[07] ← R[07] | R[07]
R[02] ← ~ R[06]
R[02] ← R[02] & R[01]
R[11] ← ~ R[04]
R[11] ← R[11] | D[02]
R[11] ← R[11] | R[07]
R[11] ← R[11] | D[01]
R[07] ← R[07] | D[07]
R[07] ← R[07] & R[07]
R[11] ← R[11] | R[07]
R[11] ← R[11] & R[02]
R[05] ← ~ R[11]
R[01] ← ~ D[06]
R[01] ← R[01] | D[04]
R[11] ← ~ D[02]
R[02] ← ~ R[11]
R[11] ← ~ D[02]
R[09] ← ~ R[01]
R[09] ← R[09] | R[02]
R[09] ← R[09] & R[01]
R[09] ← R[09] | D[01]
R[05] ← R[05] & R[09]
R[01] ← ~ R[05]
R[11] ← R[11] | D[02]
R[11] ← R[11] | D[01]
R[11] ← R[11] & D[01]
R[11] ← R[11] & R[11]
R[11] ← R[11] | D[02]
R[11] ← R[11] | D[02]
R[11] ← R[11] | D[02]
R[06] ← ~ R[11]
R[09] ← ~ D[01]
R[05] ← ~ R[11]
R[02] ← ~ R[06]
R[02] ← R[02] & R[01]
R[05] ← R[05] & D[10]
R[05] ← R[05] | R[02]
R[08] ← ~ R[09]
R[03] ← ~ D[11]
R[03] ← R[03] & R[08]
R[05] ← R[05] & R[03]
R[05] ← R[05] | R[02]
R[06] ← ~ D[04]
R[10] ← ~ R[01]
R[07] ← ~ D[09]
R[02] ← ~ R[06]
R[04] ← ~ R[02]
R[11] ← ~ R[04]
R[06] ← ~ R[11]
R[07] ← R[07] | D[07]
R[01] ← R[01] | R[05]
R[06] ← R[06] & D[03]
R[07] ← R[07] | D[09]
R[01] ← R[01] & R[11]
R[10] ← R[10] & R[06]
R[04] ← ~ R[04]
R[07] ← R[07] | D[07]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[07] ← R[07] & D[02]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[07] ← R[07] & D[02]
R[04] ← R[04] | D[02]
R[07] ← R[07] | D[07]
R[11] ← ~ R[04]
R[04] ← ~ D[01]
R[10] ← R[10] & R[11]
R[11] ← R[11] | D[02]
R[07] ← R[07] | R[07]
R[07] ← R[07] | R[07]
R[05] ← ~ R[11]
R[11] ← ~ R[04]
R[04] ← ~ R[04]
R[07] ← R[07] & D[04]
R[01] ← R[01] | R[05]
R[10] ← R[10] | D[08]
R[08] ← ~ D[04]
R[07] ← R[07] | R[08]
R[04] ← R[04] & R[10]
R[06] ← ~ R[11]
R[07] ← R[07] & D[02]
R[11] ← R[11] & D[01]
R[07] ← R[07] | D[07]
R[11] ← R[11] & D[01]
R[07] ← R[07] & R[07]
R[11] ← R[11] | R[07]
R[10] ← ~ R[01]
R[04] ← R[04] | D[02]
R[02] ← ~ R[06]
R[06] ← ~ R[02]
R[01] ← R[01] | R[05]
R[06] ← R[06] & D[03]
R[06] ← R[06] & D[03]
R[01] ← R[01] & R[11]
R[10] ← R[10] & R[06]
R[04] ← ~ R[04]
R[04] ← R[04] & R[10]
R[04] ← R[04] | D[02]
R[11] ← ~ R[04]
R[11] ← R[11] | D[02]
R[05] ← ~ R[11]
R[01] ← R[01] | R[05]
```

We then "decompile" this linear register-transfer code into a symbolic expression, which is frequently quite hairy, so we use the `sympy` symbolic computation library to simplify it to a feasibly human-readable form.

![](https://i.imgur.com/60DuNZZ.png)


![Distribution of objective performance across the eight subpopulations](https://i.imgur.com/udbdMis.png)



![Distribution of trace information across the eight subpopulations](https://i.imgur.com/r6blcOs.png)


![Interaction matrices for the 8-to-1 Multiplexor experiment](https://i.imgur.com/6uXm7Jf.png)

